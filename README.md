# HAL-Net: Hybrid Attention Lightweight Age Estimation

![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-EE4C2C.svg?style=flat-square&logo=PyTorch&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square)
![SOTA](https://img.shields.io/badge/SOTA-Competitive-success)

## ğŸ“– Project Overview (é¡¹ç›®æ¦‚è¿°)

This project implements **HAL-Net** (Hybrid Attention Lightweight Network), a high-performance age estimation system optimized for edge devices. It achieves state-of-the-art (SOTA) level accuracy on the AFAD dataset using **MobileNetV3-Large** combined with **Coordinate Attention**, **Deep Label Distribution Learning (DLDL-v2)** and strict **Stratified Sampling**.

**Key Performance Indicators:**
*   **MAE**: **3.1480** (Test SOTA Competitive)
*   **Inference Speed**: **122 FPS** (RTX 3060), **59 FPS** (Ryzen 9 CPU)
*   **Parameters**: ~5.4M
*   **FLOPs**: ~219M

---

## âœ¨ Key Features (æ ¸å¿ƒç‰¹æ€§)

1.  **Lightweight Backbone**: Built on `MobileNetV3-Large` for optimal speed/accuracy trade-off.
2.  **Hybrid Attention (New)**: Incorporates **Coordinate Attention (CA)** in deep layers (Stage 4-5) to capture spatial aging features (wrinkles, face shape) while keeping shallow layers efficient.
3.  **DLDL-v2 (Deep Label Distribution Learning)**: Enhanced DLDL with **Adaptive Sigma**, **Ranking/CDF Loss**, and **LDS** (Label Distribution Smoothing) to handle label ambiguity and imbalance.
4.  **Stratified Sampling**: Implements a rigorous `90/5/5` split based on age distribution to ensure validating on representative data.
5.  **Freeze Training Strategy**: Protects pre-trained backbone features during the initial phase of training (Warm-up + Freeze).
6.  **Advanced Reg**: Incorporates `MixUp` (alpha=0.2), `Dynamic Dropout`, and `EMA` (Exponential Moving Average) for robust generalization.

---

## ğŸ“‚ Project Structure (ç›®å½•ç»“æ„)

```text
â”œâ”€â”€ config.py             # [Core] Global configuration (Hyperparams, Paths)
â”œâ”€â”€ model.py              # [Core] Model architecture definition (MBV3 + Custom Head)
â”œâ”€â”€ dataset.py            # [Data] Dataset class, Loading, and Stratified Splitting
â”œâ”€â”€ train.py              # [Main] Training loop, Validation, Checkpointing
â”œâ”€â”€ utils.py              # [Utils] Loss functions (KL+L1+Rank), DLDL logic, EMA
â”œâ”€â”€ benchmark_speed.py    # [Tools] Interface speed benchmarking (FPS/Latency)
â”œâ”€â”€ plot_results.py       # [Tools] Generate training visualization plots
â””â”€â”€ README.md             # Project documentation
```

---

## ğŸš€ Getting Started (å¿«é€Ÿå¼€å§‹)

### 1. Requirements
```bash
pip install torch torchvision numpy pandas tqdm tensorboard matplotlib scipy
```

### 2. Configure Paths
Verify your dataset paths in `config.py`:
```python
# config.py
self.afad_dir = "./data_aligned/AFAD"
self.aaf_dir = "./data_aligned/AAF"
```

### 2.5. Data Preprocessing (æ•°æ®é¢„å¤„ç†)
Use `preprocess.py` to align faces and perform stratified splitting:
```bash
python preprocess.py
```
*   **Align Faces**: Detects and aligns faces from source datasets (AFAD/AAF).
*   **Stratified Split**: Generates `dataset_split_stratified.json` with 90/5/5 ratio.

### 3. Training (è®­ç»ƒ)
Start the training process with SOTA presets:
```bash
python train.py
```
*   **Outputs**:
    *   `best_model.pth`: Model with lowest Val MAE.
    *   `training_log.csv`: Detailed epoch-wise metrics.
    *   `runs/`: TensorBoard logs.

### 4. Evaluation & Visualization (è¯„ä¼°ä¸å¯è§†åŒ–)
Generate performance plots (Loss, MAE, LR Schedule):
```bash
python plot_results.py
```
Run hardware benchmark:
```bash
python benchmark_speed.py
```

---

## ğŸ’» Web Demo (å¯è§†åŒ–æ¼”ç¤º)

Run the interactive web interface for age estimation:
```bash
streamlit run web_demo.py
```
**Features:**
*   **Single Image Analysis**: Upload or take a snapshot to estimate age with uncertainty plots.
*   **Batch Processing**: Process multiple images at once and export results to CSV.
*   **Real-time Video**: Live age estimation from webcam feed.

---

## ğŸ“Š Benchmark Results (AFAD Dataset)

| Model | Backbone | Params | MAE (Lower is Better) |
| :--- | :--- | :--- | :--- |
| **Ours** | **MobileNetV3** | **5.4M** | **3.1480** |
| ResNet-18 | ResNet-18 | 11.7M | ~3.11 |
| GhostNet | GhostNet | 5.2M | N/A (Theoretical) |
| OR-CNN | VGG-16 | 138M | 3.34 |

---

## ğŸ“ License
This project is open-source and available under the MIT License.

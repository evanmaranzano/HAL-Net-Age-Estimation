import os
import torch

# Define Project Root (src is one level deep)
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

class Config:
    # --- 1. ğŸ”¬ Ablation Switch (æ¶ˆèå®éªŒæ ¸å¿ƒå¼€å…³) ---
    use_hybrid_attention = True  # HA: Coordinate Attention
    use_dldl_v2 = True           # DLDL: Adaptive Sigma + Rank Loss
    use_multi_scale = True       # MSFF: Texture-Semantics Dual-Stream
    use_spp = True               # SPP: Bottleneck SPP v2 (Global-Local Fusion)
    
    # --- 1.1 ğŸ“Š Split Protocol (New) ---
    # Options: '90-5-5' (Our Best) or '72-8-20' (Standard 80-20 implementation)
    split_protocol = '80-10-10'

    # --- 1.2 ğŸŒ± Academic Seeds (with Meanings) ---
    ACADEMIC_SEEDS = {
        42:   "The Answer to Life, the Universe, and Everything",
        3407: '"Torch.manual_seed(3407) is all you need" (arXiv:2109.08203)',
        2026: "Current Year (Modernity Check)",
        1337: "Leet (Elite)",
        1106: "Special Dedication <3 (Randomly Sampled w.r.t our hearts)",
        2027: "The Robustness Overhaul (Correction of 2026's Hubris)"
    }

    # --- 2. ğŸš€ åŠ¨æ€é¡¹ç›®å‘½åé€»è¾‘ (Robust & Dynamic) ---
    @property
    def project_name(self):
        base = "FADE-Net"
        tags = []
        if self.use_hybrid_attention: tags.append("HA")
        if self.use_dldl_v2:          tags.append("DLDL")
        if self.use_multi_scale:      tags.append("MSFF")
        if self.use_spp:              tags.append("SPP")
        if getattr(self, 'use_mv_loss', False): tags.append("MV")
        
        suffix = "_".join(tags) if tags else "Baseline"
        return f"{base}_{suffix}"

    # --- 3. ğŸ¯ æ ¸å¿ƒè¶…å‚æ•° (Based on Final Tuning) ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # å¹´é¾„åŒºé—´
    min_age, max_age = 0, 80
    num_classes = 81 
    
    # DLDL-v2 åŠ¨æ€å¾®è°ƒå‚æ•°
    use_adaptive_sigma = True
    sigma_min = 1.0              # ğŸ›¡ï¸ Rescue: Sharpened back to 1.0 (Precision)
    sigma_max = 3.0              # ğŸ›¡ï¸ Rescue: Tightened upper bound
    lambda_l1 = 0.1              # ğŸ“‰ Oracle: 0.1
    lambda_rank = 0.5            # ğŸ‘‘ 2027b: Reduced to 0.5 to prevent Rank-L1 conflict

    # Mean-Variance Loss (Nuclear Weapon)
    use_mv_loss = True
    lambda_mv = 0.1
    
    # Label-Level Perturbation (Sigma Jitter)
    use_sigma_jitter = True
    sigma_jitter = 0.2
    
    # è®­ç»ƒ/ä¼˜åŒ–
    batch_size = 128             # ğŸš€ Increased for A10 (24GB VRAM) utilization
    learning_rate = 0.0003       #ä¿æŒ 3e-4
    weight_decay = 4e-4          # âš–ï¸ 2027c: Increased to 4e-4 (Standard AdamW)
    epochs = 120
    
    # è®­ç»ƒç­–ç•¥
    freeze_backbone_epochs = 10  # Keep 10 for safety
    
    # æ•°æ®å¢å¼ºä¸æ­£åˆ™åŒ–
    # æ•°æ®å¢å¼ºä¸æ­£åˆ™åŒ–
    dropout = 0.35               # âš–ï¸ 2027d: Adjusted to 0.35 (Rescue 1106: Stronger Regularization)
    use_mixup = True             # âœ… Re-enabled: Essential for Manifold Smoothing & Generalization
    
    # âœ… [Added] Random Erasing as Compensation
    use_random_erasing = True    # ğŸ›¡ï¸ Balanced: Enabled (Light regularization)
    re_prob = 0.1                # ğŸ›¡ï¸ Balanced: 0.1 (Conservative but robust)
    
    mixup_alpha = 0.5            # ğŸ¸ Oracle: 0.5 (Standard Mixup)
    mixup_prob = 0.5
    
    use_ema = True
    ema_decay = 0.999            # ğŸ›¡ï¸ ä»¥ EMA ä¸ºå‡†
    
    # æ ‡ç­¾å¹³æ»‘ (Label Smoothing)
    label_smoothing = 0.0        # ç¦ç”¨ï¼Œé¿å…æ±¡æŸ“ DLDL åˆ†å¸ƒ
    
    # æ•°æ®é›†å¼€å…³ (Set use_aaf=False for pure academic benchmark)
    use_afad = True
    use_aaf = False   # é»˜è®¤å¼€å¯ä»¥å¢å¼ºé²æ£’æ€§ï¼Œè‹¥éœ€å¯¹æ¯” SOTA è¯·è®¾ä¸º False

    # æ•°æ®é›†è·¯å¾„ relative to ROOT_DIR
    afad_dir = os.path.join(ROOT_DIR, "datasets", "AFAD")
    aaf_dir = os.path.join(ROOT_DIR, "datasets", "AAF")
    
    # LDS (æ ‡ç­¾åˆ†å¸ƒå¹³æ»‘)
    use_reweighting = True
    use_alignment = False
    
    lds_sigma = 4                # ğŸ“‰ Oracle: 4 (Stronger LDS smoothing)
    
    # å›¾ç‰‡å‚æ•°
    img_size = 224
    num_workers = 4              # ğŸï¸ Optimized for CPU usage (avoid 100% load)
    early_stopping_patience = 999 # ğŸ›¡ï¸ 2027 Strategy: "Trust the Process". Let Cosine Annealing finish its full cycle.

    def __init__(self):
        pass # Attributes are class-level or properties
        
    def __repr__(self):
        return f"ğŸš€ Starting Project: {self.project_name} on {self.device}"
